{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_regression_softmax",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MingSheng92/Image_Classification/blob/master/Logistic_regression_softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvnyLIK0kJRR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "33a7e32a-3199-4f3b-dd12-8c49a9d87324"
      },
      "source": [
        "!git clone https://github.com/MingSheng92/Image_Classification.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Image_Classification'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/62)\u001b[K\rremote: Counting objects:   3% (2/62)\u001b[K\rremote: Counting objects:   4% (3/62)\u001b[K\rremote: Counting objects:   6% (4/62)\u001b[K\rremote: Counting objects:   8% (5/62)\u001b[K\rremote: Counting objects:   9% (6/62)\u001b[K\rremote: Counting objects:  11% (7/62)\u001b[K\rremote: Counting objects:  12% (8/62)\u001b[K\rremote: Counting objects:  14% (9/62)\u001b[K\rremote: Counting objects:  16% (10/62)\u001b[K\rremote: Counting objects:  17% (11/62)\u001b[K\rremote: Counting objects:  19% (12/62)\u001b[K\rremote: Counting objects:  20% (13/62)\u001b[K\rremote: Counting objects:  22% (14/62)\u001b[K\rremote: Counting objects:  24% (15/62)\u001b[K\rremote: Counting objects:  25% (16/62)\u001b[K\rremote: Counting objects:  27% (17/62)\u001b[K\rremote: Counting objects:  29% (18/62)\u001b[K\rremote: Counting objects:  30% (19/62)\u001b[K\rremote: Counting objects:  32% (20/62)\u001b[K\rremote: Counting objects:  33% (21/62)\u001b[K\rremote: Counting objects:  35% (22/62)\u001b[K\rremote: Counting objects:  37% (23/62)\u001b[K\rremote: Counting objects:  38% (24/62)\u001b[K\rremote: Counting objects:  40% (25/62)\u001b[K\rremote: Counting objects:  41% (26/62)\u001b[K\rremote: Counting objects:  43% (27/62)\u001b[K\rremote: Counting objects:  45% (28/62)\u001b[K\rremote: Counting objects:  46% (29/62)\u001b[K\rremote: Counting objects:  48% (30/62)\u001b[K\rremote: Counting objects:  50% (31/62)\u001b[K\rremote: Counting objects:  51% (32/62)\u001b[K\rremote: Counting objects:  53% (33/62)\u001b[K\rremote: Counting objects:  54% (34/62)\u001b[K\rremote: Counting objects:  56% (35/62)\u001b[K\rremote: Counting objects:  58% (36/62)\u001b[K\rremote: Counting objects:  59% (37/62)\u001b[K\rremote: Counting objects:  61% (38/62)\u001b[K\rremote: Counting objects:  62% (39/62)\u001b[K\rremote: Counting objects:  64% (40/62)\u001b[K\rremote: Counting objects:  66% (41/62)\u001b[K\rremote: Counting objects:  67% (42/62)\u001b[K\rremote: Counting objects:  69% (43/62)\u001b[K\rremote: Counting objects:  70% (44/62)\u001b[K\rremote: Counting objects:  72% (45/62)\u001b[K\rremote: Counting objects:  74% (46/62)\u001b[K\rremote: Counting objects:  75% (47/62)\u001b[K\rremote: Counting objects:  77% (48/62)\u001b[K\rremote: Counting objects:  79% (49/62)\u001b[K\rremote: Counting objects:  80% (50/62)\u001b[K\rremote: Counting objects:  82% (51/62)\u001b[K\rremote: Counting objects:  83% (52/62)\u001b[K\rremote: Counting objects:  85% (53/62)\u001b[K\rremote: Counting objects:  87% (54/62)\u001b[K\rremote: Counting objects:  88% (55/62)\u001b[K\rremote: Counting objects:  90% (56/62)\u001b[K\rremote: Counting objects:  91% (57/62)\u001b[K\rremote: Counting objects:  93% (58/62)\u001b[K\rremote: Counting objects:  95% (59/62)\u001b[K\rremote: Counting objects:  96% (60/62)\u001b[K\rremote: Counting objects:  98% (61/62)\u001b[K\rremote: Counting objects: 100% (62/62)\u001b[K\rremote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/62)\u001b[K\rremote: Compressing objects:   3% (2/62)\u001b[K\rremote: Compressing objects:   4% (3/62)\u001b[K\rremote: Compressing objects:   6% (4/62)\u001b[K\rremote: Compressing objects:   8% (5/62)\u001b[K\rremote: Compressing objects:   9% (6/62)\u001b[K\rremote: Compressing objects:  11% (7/62)\u001b[K\rremote: Compressing objects:  12% (8/62)\u001b[K\rremote: Compressing objects:  14% (9/62)\u001b[K\rremote: Compressing objects:  16% (10/62)\u001b[K\rremote: Compressing objects:  17% (11/62)\u001b[K\rremote: Compressing objects:  19% (12/62)\u001b[K\rremote: Compressing objects:  20% (13/62)\u001b[K\rremote: Compressing objects:  22% (14/62)\u001b[K\rremote: Compressing objects:  24% (15/62)\u001b[K\rremote: Compressing objects:  25% (16/62)\u001b[K\rremote: Compressing objects:  27% (17/62)\u001b[K\rremote: Compressing objects:  29% (18/62)\u001b[K\rremote: Compressing objects:  30% (19/62)\u001b[K\rremote: Compressing objects:  32% (20/62)\u001b[K\rremote: Compressing objects:  33% (21/62)\u001b[K\rremote: Compressing objects:  35% (22/62)\u001b[K\rremote: Compressing objects:  37% (23/62)\u001b[K\rremote: Compressing objects:  38% (24/62)\u001b[K\rremote: Compressing objects:  40% (25/62)\u001b[K\rremote: Compressing objects:  41% (26/62)\u001b[K\rremote: Compressing objects:  43% (27/62)\u001b[K\rremote: Compressing objects:  45% (28/62)\u001b[K\rremote: Compressing objects:  46% (29/62)\u001b[K\rremote: Compressing objects:  48% (30/62)\u001b[K\rremote: Compressing objects:  50% (31/62)\u001b[K\rremote: Compressing objects:  51% (32/62)\u001b[K\rremote: Compressing objects:  53% (33/62)\u001b[K\rremote: Compressing objects:  54% (34/62)\u001b[K\rremote: Compressing objects:  56% (35/62)\u001b[K\rremote: Compressing objects:  58% (36/62)\u001b[K\rremote: Compressing objects:  59% (37/62)\u001b[K\rremote: Compressing objects:  61% (38/62)\u001b[K\rremote: Compressing objects:  62% (39/62)\u001b[K\rremote: Compressing objects:  64% (40/62)\u001b[K\rremote: Compressing objects:  66% (41/62)\u001b[K\rremote: Compressing objects:  67% (42/62)\u001b[K\rremote: Compressing objects:  69% (43/62)\u001b[K\rremote: Compressing objects:  70% (44/62)\u001b[K\rremote: Compressing objects:  72% (45/62)\u001b[K\rremote: Compressing objects:  74% (46/62)\u001b[K\rremote: Compressing objects:  75% (47/62)\u001b[K\rremote: Compressing objects:  77% (48/62)\u001b[K\rremote: Compressing objects:  79% (49/62)\u001b[K\rremote: Compressing objects:  80% (50/62)\u001b[K\rremote: Compressing objects:  82% (51/62)\u001b[K\rremote: Compressing objects:  83% (52/62)\u001b[K\rremote: Compressing objects:  85% (53/62)\u001b[K\rremote: Compressing objects:  87% (54/62)\u001b[K\rremote: Compressing objects:  88% (55/62)\u001b[K\rremote: Compressing objects:  90% (56/62)\u001b[K\rremote: Compressing objects:  91% (57/62)\u001b[K\rremote: Compressing objects:  93% (58/62)\u001b[K\rremote: Compressing objects:  95% (59/62)\u001b[K\rremote: Compressing objects:  96% (60/62)\u001b[K\rremote: Compressing objects:  98% (61/62)\u001b[K\rremote: Compressing objects: 100% (62/62)\u001b[K\rremote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "Receiving objects:   0% (1/160)   \rReceiving objects:   1% (2/160)   \rReceiving objects:   2% (4/160)   \rReceiving objects:   3% (5/160)   \rReceiving objects:   4% (7/160)   \rReceiving objects:   5% (8/160)   \rReceiving objects:   6% (10/160)   \rReceiving objects:   7% (12/160)   \rReceiving objects:   8% (13/160)   \rReceiving objects:   9% (15/160)   \rReceiving objects:  10% (16/160)   \rReceiving objects:  11% (18/160)   \rReceiving objects:  12% (20/160)   \rReceiving objects:  13% (21/160)   \rReceiving objects:  14% (23/160)   \rReceiving objects:  15% (24/160)   \rReceiving objects:  16% (26/160)   \rReceiving objects:  17% (28/160)   \rReceiving objects:  18% (29/160)   \rReceiving objects:  19% (31/160)   \rReceiving objects:  20% (32/160)   \rReceiving objects:  21% (34/160)   \rReceiving objects:  22% (36/160)   \rReceiving objects:  23% (37/160)   \rReceiving objects:  24% (39/160)   \rReceiving objects:  25% (40/160)   \rReceiving objects:  26% (42/160)   \rReceiving objects:  27% (44/160)   \rReceiving objects:  28% (45/160)   \rReceiving objects:  29% (47/160)   \rReceiving objects:  30% (48/160)   \rReceiving objects:  31% (50/160)   \rReceiving objects:  32% (52/160)   \rReceiving objects:  33% (53/160)   \rReceiving objects:  34% (55/160)   \rReceiving objects:  35% (56/160)   \rReceiving objects:  36% (58/160)   \rReceiving objects:  37% (60/160)   \rReceiving objects:  38% (61/160)   \rReceiving objects:  39% (63/160)   \rReceiving objects:  40% (64/160)   \rReceiving objects:  41% (66/160)   \rReceiving objects:  42% (68/160)   \rReceiving objects:  43% (69/160)   \rReceiving objects:  44% (71/160)   \rReceiving objects:  45% (72/160)   \rReceiving objects:  46% (74/160)   \rReceiving objects:  47% (76/160)   \rReceiving objects:  48% (77/160)   \rReceiving objects:  49% (79/160)   \rReceiving objects:  50% (80/160)   \rReceiving objects:  51% (82/160)   \rReceiving objects:  52% (84/160)   \rReceiving objects:  53% (85/160)   \rReceiving objects:  54% (87/160)   \rReceiving objects:  55% (88/160)   \rReceiving objects:  56% (90/160)   \rReceiving objects:  57% (92/160)   \rReceiving objects:  58% (93/160)   \rReceiving objects:  59% (95/160)   \rReceiving objects:  60% (96/160)   \rReceiving objects:  61% (98/160)   \rReceiving objects:  62% (100/160)   \rReceiving objects:  63% (101/160)   \rReceiving objects:  64% (103/160)   \rReceiving objects:  65% (104/160)   \rReceiving objects:  66% (106/160)   \rReceiving objects:  67% (108/160)   \rReceiving objects:  68% (109/160)   \rReceiving objects:  69% (111/160)   \rReceiving objects:  70% (112/160)   \rReceiving objects:  71% (114/160)   \rReceiving objects:  72% (116/160)   \rReceiving objects:  73% (117/160)   \rReceiving objects:  74% (119/160)   \rReceiving objects:  75% (120/160)   \rReceiving objects:  76% (122/160)   \rReceiving objects:  77% (124/160)   \rReceiving objects:  78% (125/160)   \rReceiving objects:  79% (127/160)   \rReceiving objects:  80% (128/160)   \rReceiving objects:  81% (130/160)   \rReceiving objects:  82% (132/160)   \rReceiving objects:  83% (133/160)   \rReceiving objects:  84% (135/160)   \rReceiving objects:  85% (136/160)   \rReceiving objects:  86% (138/160)   \rReceiving objects:  87% (140/160)   \rReceiving objects:  88% (141/160)   \rReceiving objects:  89% (143/160)   \rReceiving objects:  90% (144/160)   \rReceiving objects:  91% (146/160)   \rReceiving objects:  92% (148/160)   \rReceiving objects:  93% (149/160)   \rReceiving objects:  94% (151/160)   \rReceiving objects:  95% (152/160)   \rremote: Total 160 (delta 26), reused 0 (delta 0), pack-reused 98\u001b[K\n",
            "Receiving objects:  96% (154/160)   \rReceiving objects:  97% (156/160)   \rReceiving objects:  98% (157/160)   \rReceiving objects:  99% (159/160)   \rReceiving objects: 100% (160/160)   \rReceiving objects: 100% (160/160), 202.88 KiB | 841.00 KiB/s, done.\n",
            "Resolving deltas:   0% (0/68)   \rResolving deltas:  35% (24/68)   \rResolving deltas:  36% (25/68)   \rResolving deltas:  42% (29/68)   \rResolving deltas:  48% (33/68)   \rResolving deltas:  51% (35/68)   \rResolving deltas:  70% (48/68)   \rResolving deltas:  75% (51/68)   \rResolving deltas:  86% (59/68)   \rResolving deltas:  91% (62/68)   \rResolving deltas:  98% (67/68)   \rResolving deltas: 100% (68/68)   \rResolving deltas: 100% (68/68), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woP6UeQukQ7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "9ae06154-3488-4558-f1df-127bc6bef807"
      },
      "source": [
        "%load /content/Image_Classification/scripts/preprocess.py\n",
        "%load /content/Image_Classification/scripts/PCA.py\n",
        "%load /content/Image_Classification/scripts/Bernoulli_NB.py\n",
        "%load /content/Image_Classification/scripts/utility.py\n",
        "\n",
        "from Image_Classification.scripts.preprocess import load_data, normalize, one_hot, flatten_image\n",
        "from Image_Classification.scripts.Bernoulli_NB import NaiveBayes\n",
        "from Image_Classification.scripts.PCA import PCA\n",
        "from Image_Classification.scripts.utility import plot_predictions\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdPJIbyCkUU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "75cfd114-d109-454f-91df-f02cb44f31d8"
      },
      "source": [
        "#dataset='fashion_mnist'\n",
        "dataset='mnist'\n",
        "# load data set \n",
        "x_train, y_train, x_test, y_test = load_data(dataset, reshape=False)\n",
        "\n",
        "# normalize the data set\n",
        "x_train = normalize(x_train)\n",
        "x_test = normalize(x_test)\n",
        "\n",
        "x_train = flatten_image(x_train)\n",
        "x_test = flatten_image(x_test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBhoSIOakXQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(Z):\n",
        "    #Z = softmax(X.dot(self.W))\n",
        "    #z1 = np.add(Z, -Z.max(axis=0))\n",
        "    e_Z = np.exp(Z)\n",
        "    A = e_Z / e_Z.sum(axis = 1, keepdims = True)\n",
        "    return A\n",
        "\n",
        "def get_accuracy(y_pre,y):\n",
        "    count = y_pre == y\n",
        "    accuracy = count.sum()/len(count)\n",
        "    return accuracy\n",
        "    \n",
        "class LogisticRegression(object):\n",
        "    # initialize class value for later processing purpose\n",
        "    def __init__(self, dataset, label):\n",
        "        self.num_inputs  = dataset.shape[1]\n",
        "        self.num_classes = len(set(label))\n",
        "        self.X           = dataset\n",
        "        self.y           = label\n",
        "        self.W           = np.random.randn(self.num_inputs, self.num_classes)\n",
        "        self.b           = np.zeros([self.num_classes,1], dtype=float)\n",
        "\n",
        "    # calculate gradient \n",
        "    def softmax_grad(self, X, y):\n",
        "        A = softmax(X.dot(self.W))     # shape of (N, C)\n",
        "        id0 = range(X.shape[0])  # number of train data\n",
        "        A[id0, y] -= 1           # A - Y, shape of (N, C)\n",
        "        return X.T.dot(A)/X.shape[0] \n",
        "\n",
        "    # cost or loss function  \n",
        "    # removed Transition matrix dot here because \n",
        "    def softmax_loss(self):\n",
        "        A = softmax(self.X.dot(self.W)) \n",
        "        id0  = range(self.X.shape[0])\n",
        "        loss = -np.mean(np.log(A[id0, self.y]))\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def eval(self, val_x, val_y):\n",
        "        # calculate loss\n",
        "        A = softmax(val_x.dot(self.W))\n",
        "        id0 = range(val_x.shape[0])\n",
        "        val_loss = -np.mean(np.log(A[id0, val_y]))\n",
        "        \n",
        "        # calculate accuracy \n",
        "        y_pred  = self.predict(val_x)\n",
        "        val_acc = get_accuracy(y_pred, val_y)\n",
        "        \n",
        "        return val_loss, val_acc\n",
        "        \n",
        "    # train softmax logistic regression\n",
        "    def train(self, train_x, train_y, val_x, val_y, lr = 0.01, n_epoches = 150, tol = 1e-5, batch_size = 10):\n",
        "        # keep a copy of weights to for weight update later\n",
        "        W_old = self.W.copy()\n",
        "        ep = 0 \n",
        "        # store history of loss\n",
        "        loss_hist = [self.softmax_loss()] \n",
        "        #loss_hist = []\n",
        "        N = train_x.shape[0]\n",
        "        nbatches = int(np.ceil(float(N)/batch_size))\n",
        "        while ep < n_epoches: \n",
        "            ep += 1 \n",
        "            mix_ids = np.random.permutation(N) # mix data \n",
        "            \n",
        "            # run by batch\n",
        "            for i in range(nbatches):\n",
        "                # get the i-th batch\n",
        "                batch_ids = mix_ids[batch_size*i:min(batch_size*(i+1), N)] \n",
        "                X_batch, y_batch = train_x[batch_ids], train_y[batch_ids]\n",
        "                self.W -= lr * self.softmax_grad(X_batch, y_batch)\n",
        "                \n",
        "            # evaluate current model\n",
        "            if ep % 10 == 0 or ep == 1:\n",
        "                val_loss, val_acc = self.eval(val_x, val_y)\n",
        "                message = 'Epoch %d, val Loss %.4f, val Acc %.4f' % (ep, val_loss, val_acc)\n",
        "                print(message)\n",
        "            \n",
        "            # append history\n",
        "            loss_hist.append(self.softmax_loss())\n",
        "            \n",
        "            # stop the looping process if the improvement rate is too low\n",
        "            if np.linalg.norm(self.W - W_old)/self.W.size < tol:\n",
        "                print('reached tolerance level.')\n",
        "                break \n",
        "                \n",
        "            # update previous W to new W for next interation\n",
        "            W_old = self.W.copy()\n",
        "\n",
        "        return loss_hist \n",
        "    \n",
        "    # predict function\n",
        "    def predict(self, X):\n",
        "        A = softmax(X.dot(self.W))\n",
        "        return np.argmax(A, axis = 1)\n",
        "    \n",
        "    # return probability of classes\n",
        "    def predict_proba(self, X):\n",
        "        A = softmax(X.dot(self.W))\n",
        "        return A \n",
        "    \n",
        "    def cross_fold(self, lr=0.01, K=10, n_epoches=50):\n",
        "        # create K fold on the current dataset\n",
        "        fold_count = 1\n",
        "        k_fold = KFold(n_splits=K, random_state=None, shuffle=False)\n",
        "\n",
        "        # perform K-fold cv\n",
        "        for train_idx, val_idx in k_fold.split(self.X):\n",
        "            print(\"Fold :\", fold_count)\n",
        "            self.train(self.X[train_idx], self.y[train_idx], self.X[val_idx], self.y[val_idx],\n",
        "                       lr, n_epoches, tol = 1e-5, batch_size = 300)\n",
        "            print(\"--------------------------------------------------------\")\n",
        "            fold_count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS8hpBOgpSE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "c9c8d2ac-ae82-4d45-b623-fbba46bba30b"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "lg = LogisticRegression(x_train, y_train)\n",
        "lg.cross_fold()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold : 1\n",
            "Epoch 1, val Loss 7.3253, val Acc 0.2280\n",
            "Epoch 10, val Loss 2.2135, val Acc 0.6172\n",
            "Epoch 20, val Loss 1.4847, val Acc 0.7202\n",
            "Epoch 30, val Loss 1.2078, val Acc 0.7643\n",
            "Epoch 40, val Loss 1.0562, val Acc 0.7907\n",
            "Epoch 50, val Loss 0.9591, val Acc 0.8083\n",
            "--------------------------------------------------------\n",
            "Fold : 2\n",
            "Epoch 1, val Loss 1.0150, val Acc 0.8002\n",
            "Epoch 10, val Loss 0.9530, val Acc 0.8103\n",
            "Epoch 20, val Loss 0.8986, val Acc 0.8185\n",
            "Epoch 30, val Loss 0.8546, val Acc 0.8260\n",
            "Epoch 40, val Loss 0.8184, val Acc 0.8327\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 3\n",
            "Epoch 1, val Loss 0.9016, val Acc 0.8128\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 4\n",
            "Epoch 1, val Loss 0.7709, val Acc 0.8440\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 5\n",
            "Epoch 1, val Loss 0.7748, val Acc 0.8380\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 6\n",
            "Epoch 1, val Loss 0.8408, val Acc 0.8220\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 7\n",
            "Epoch 1, val Loss 0.8508, val Acc 0.8223\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 8\n",
            "Epoch 1, val Loss 0.8416, val Acc 0.8303\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 9\n",
            "Epoch 1, val Loss 0.8566, val Acc 0.8230\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 10\n",
            "Epoch 1, val Loss 0.6329, val Acc 0.8617\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzO7HyJfvfvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = lg.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO8yHiWeRswc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d99e4c0f-ab86-499b-e0db-9906823715cc"
      },
      "source": [
        "acc = get_accuracy(y_pred, y_test)\n",
        "print(acc*100.)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83.74000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de8Y-dIoSs6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a4705208-bcdc-425b-ea33-6193228e1aec"
      },
      "source": [
        "dataset='fashion_mnist'\n",
        "\n",
        "# load data set \n",
        "x_train, y_train, x_test, y_test = load_data(dataset, reshape=False)\n",
        "\n",
        "# normalize the data set\n",
        "x_train = normalize(x_train)\n",
        "x_test = normalize(x_test)\n",
        "\n",
        "x_train = flatten_image(x_train)\n",
        "x_test = flatten_image(x_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 1us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1AnZW3fS2yR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "8b485bd6-5440-4176-bcf3-ee1317a31504"
      },
      "source": [
        "lg = LogisticRegression(x_train, y_train)\n",
        "lg.cross_fold()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold : 1\n",
            "Epoch 1, val Loss 6.4991, val Acc 0.2393\n",
            "Epoch 10, val Loss 2.4028, val Acc 0.5768\n",
            "Epoch 20, val Loss 1.8572, val Acc 0.6397\n",
            "Epoch 30, val Loss 1.6137, val Acc 0.6735\n",
            "Epoch 40, val Loss 1.4697, val Acc 0.6955\n",
            "Epoch 50, val Loss 1.3717, val Acc 0.7107\n",
            "--------------------------------------------------------\n",
            "Fold : 2\n",
            "Epoch 1, val Loss 1.3843, val Acc 0.7097\n",
            "Epoch 10, val Loss 1.3187, val Acc 0.7197\n",
            "Epoch 20, val Loss 1.2610, val Acc 0.7315\n",
            "Epoch 30, val Loss 1.2124, val Acc 0.7363\n",
            "Epoch 40, val Loss 1.1718, val Acc 0.7432\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 3\n",
            "Epoch 1, val Loss 1.0822, val Acc 0.7425\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 4\n",
            "Epoch 1, val Loss 1.0723, val Acc 0.7530\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 5\n",
            "Epoch 1, val Loss 1.1297, val Acc 0.7408\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 6\n",
            "Epoch 1, val Loss 1.0737, val Acc 0.7563\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 7\n",
            "Epoch 1, val Loss 1.0829, val Acc 0.7592\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 8\n",
            "Epoch 1, val Loss 1.0825, val Acc 0.7507\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 9\n",
            "Epoch 1, val Loss 1.0717, val Acc 0.7535\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n",
            "Fold : 10\n",
            "Epoch 1, val Loss 1.0558, val Acc 0.7525\n",
            "reached tolerance level.\n",
            "--------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leMCEHzxTTZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63906357-3cbe-441b-bbe9-6274d206fdd8"
      },
      "source": [
        "y_pred = lg.predict(x_test)\n",
        "acc = get_accuracy(y_pred, y_test)\n",
        "print(acc*100.)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.61999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}